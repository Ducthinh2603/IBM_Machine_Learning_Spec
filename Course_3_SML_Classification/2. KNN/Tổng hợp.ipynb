{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4003362f",
   "metadata": {},
   "source": [
    "# Week 1\n",
    "## I. Logistic Regression \n",
    "### 1. Classification Error Matrix  \n",
    "**1.1. F1 Score**   \n",
    "\n",
    "|                  | Predicted Positive | Predicted Negative |\n",
    "|------------------|--------------------|--------------------|\n",
    "|  Actual Positive | TP                 | FN                 |  \n",
    "|  Actual Negative | FP                 | TN                 |\n",
    "\n",
    "**FP: Type I Error**  \n",
    "**FN: Type II Error**  \n",
    "_$=> p value$_  \n",
    "\n",
    "**- Predicted Correctly:**  \n",
    "$${\\displaystyle {\\text{Accuracy}}={\\frac {TP+TN}{TP+TN+FP+FN}}}$$ -> Maybe deceived if model is skewed\n",
    "\n",
    "**- Identify All Positive Instances:**  \n",
    "$${\\displaystyle {\\text{Recall/Sensitivity}}={\\frac {TP}{TP+FN}}}$$\n",
    "\n",
    "$${\\displaystyle ={\\frac {Correct Predicted Positive}{Actual Positive}}}$$ \n",
    "\n",
    "**- Identify Only Positive Instances:**\n",
    "$${\\displaystyle {\\text{Precision}}={\\frac {TP}{TP+FP}}}$$\n",
    "\n",
    "$${\\displaystyle ={\\frac {Correct Predicted Positive}{Total Predicted Positive}}}$$\n",
    "\n",
    "**- Avoid False Alarms:**\n",
    "$${\\displaystyle {\\text{Specificity}}={\\frac {TN}{TN+FP}}}$$\n",
    "\n",
    "$${\\displaystyle ={\\frac {Correct Predicted Negative}{Actual Negative}}}$$\n",
    "\n",
    "**- F1 score:**\n",
    "$${\\displaystyle {\\text{F1_score}}={2\\frac {Precision * Recall}{Precision + Recall}}}$$\n",
    "\n",
    "**1.2. ROC and Precision-Recall Curves**  \n",
    "- _Receiver Operating Characteristic (ROC)_: True Positive Rate (Sensitivity) vs False Positive Rate (1 - Specification)\n",
    "    - Generally better for data with balanced classes\n",
    "- _Precision-Recall Curves_: Precision vs Recall\n",
    "    - Generally better for data with imbalanced classes\n",
    "\n",
    "**All Classification Error Matrix is in ```sklearn.metrics```**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24c2b7f3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
